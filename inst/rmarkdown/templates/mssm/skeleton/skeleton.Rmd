---
title: "Meta-Workflow"
author: "Miao Yu"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache = T,message=T,warning=F)
library(rmwf)
sessionInfo()
```

![logo](logo.png)

# Optimization and peak picking

## Optimization

This chunk should run first to generate IPO parameters. We suggest a computer with large memory to run this chunk.

```{r IPOpos,eval=FALSE}
library(IPO)
library(xcms)
peakpickingParameters <- getDefaultXcmsSetStartingParams('centWave')
# Demo data
path <- system.file("extdata/plasma", package = "rmwf")
# Uncomment this line to use your own data(suggested 3-5 pooled QC samples)
# path <- 'path/to/your/files'
# change to 5 for obitrap
peakpickingParameters$ppm <- 10
resultPeakpicking <- 
  optimizeXcmsSet(files = path, 
                  params = peakpickingParameters,
                  plot = F,
                  subdir = NULL)

optimizedXcmsSetObject <- resultPeakpicking$best_settings$xset
retcorGroupParameters <- getDefaultRetGroupStartingParams()
resultRetcorGroup <-
  optimizeRetGroup(xset = optimizedXcmsSetObject, 
                   params = retcorGroupParameters, 
                   plot = F,
                   subdir = NULL)
writeRScript(resultPeakpicking$best_settings$parameters, 
             resultRetcorGroup$best_settings)
para <- capture.output(writeRScript(resultPeakpicking$best_settings$parameters, resultRetcorGroup$best_settings), type = "message")
save(para,file = 'para.RData')
sessionInfo()
```

## Wrap function for peak picking

This chunk could be run after you have `para.RData` from last chunk.

```{r eval=F}
library(xcms)
library(Rmpi)
library(stringr)
# here we use pre-optimized IPO parameters
data('para')
getrtmz <- function(path,index = NULL){
peakwidth <- as.numeric(unlist(str_extract_all(para[grepl('peakwidth',para)],'\\d+\\.*\\d*')))
ppm <- as.numeric(unlist(str_extract_all(para[grepl('ppm',para)],'\\d+')))
noise <- as.numeric(unlist(str_extract_all(para[grepl('noise',para)],'\\d+')))
snthresh <- as.numeric(unlist(str_extract_all(para[grepl('snthresh',para)],'\\d+')))
mzdiff <- as.numeric(unlist(str_extract_all(para[grepl('mzdiff',para)],'\\d+\\.*\\d*')))
prefilter <- as.numeric(unlist(str_extract_all(para[grepl('prefilter',para)],'\\d+\\.*\\d*')))
integrate <- as.numeric(unlist(str_extract_all(para[grepl('integrate',para)],'\\d+')))
profStep <- round(as.numeric(unlist(str_extract_all(para[grepl('profStep',para)],'\\d+\\.*\\d*'))),1)
center <- as.numeric(unlist(str_extract_all(para[grepl('center',para)],'\\d+')))
response <- as.numeric(unlist(str_extract_all(para[grepl('response',para)],'\\d+')))
gapInit <- as.numeric(unlist(str_extract_all(para[grepl('gapInit',para)],'\\d+\\.*\\d*')))
gapExtend <- as.numeric(unlist(str_extract_all(para[grepl('gapExtend',para)],'\\d+\\.*\\d*')))
factorDiag <- as.numeric(unlist(str_extract_all(para[grepl('factorDiag',para)],'\\d+')))
factorGap <- as.numeric(unlist(str_extract_all(para[grepl('factorGap',para)],'\\d+')))
localAlignment <- as.numeric(unlist(str_extract_all(para[grepl('localAlignment',para)],'\\d+')))
bw <- as.numeric(unlist(str_extract_all(para[grepl('bw',para)],'\\d+\\.*\\d*')))
mzwid <- as.numeric(unlist(str_extract_all(para[grepl('mzwid',para)],'\\d+\\.*\\d*')))
minfrac <- as.numeric(unlist(str_extract_all(para[grepl('minfrac',para)],'\\d+\\.*\\d*')))
minsamp <- as.numeric(unlist(str_extract_all(para[grepl('minsamp',para)],'\\d+')))
max <-  as.numeric(unlist(str_extract_all(para[grepl('max',para)],'\\d+')))
  files <- list.files(path,full.names = T,recursive = T)
  if(!is.null(index)){
    files <- files[index]
  }
  xset <- xcmsSet(files,
  method = "centWave",
  peakwidth       = peakwidth,
  ppm             = ppm,
  noise           = noise,
  snthresh        = snthresh,
  mzdiff          = mzdiff,
  prefilter       = prefilter,
  mzCenterFun     = "wMean",
  integrate       = integrate,
  fitgauss        = FALSE,
  verbose.columns = FALSE)
xset <- retcor( 
  xset,
  method         = "obiwarp",
  plottype       = "none",
  distFunc       = "cor_opt",
  profStep       = profStep,
  center         = center,
  response       = response,
  gapInit        = gapInit,
  gapExtend      = gapExtend,
  factorDiag     = factorDiag,
  factorGap      = factorGap,
  localAlignment = localAlignment)
xset <- group( 
  xset,
  method  = "density",
  bw      = bw,
  mzwid   = mzwid,
  minfrac = minfrac,
  minsamp = minsamp,
  max     = max)

xset <- fillPeaks(xset)
return(xset)
}
```

## Peaks list

This chunk is used to generate peaks list and related csv, xcmsset object, xcmsEIC object for further analysis.

```{r eval=F}
library(enviGCMS)
# get the xcmsset object from demo data
path <- system.file("extdata/data", package = "rmwf")
# use your own data
# path <- 'path/to/your/file'
srm <- getrtmz(path)
# back up the xcmsset object, xcmsEIC object and peak list
mzrt <- getmzrt(srm, name = 'srm', eic = T, type = 'mapo')
```

# Data pre-processing

## Peaks filtering

Peaks list could be processed by experimental design in thie chunk.

```{r pf}
library(enviGCMS)
data(mzrt)
# get the mean and rsd for each group
mzrtm <- enviGCMS::getdoe(mzrt)
gm <- mzrtm$groupmean
gr <- mzrtm$grouprsd
# find the blank group and pool QC group, demo data only have matrix blank
srm <- grepl('plasma',colnames(gm))
blk <- grepl('matrix',colnames(gm))
# pqc <- grepl('pool',colnames(gm))
# filter by pool QC and blank's group mean intensity(pool QC should larger than three times of blank), return numbers and index
# in demo data, use sample average intensity for each peak
sum(indexmean <- apply(gm,1,function(x) all(x[srm]>= 3*x[blk])))
# filt by pool qc rsd%, return numbers and index
# in demo data, use sample average intensity for each peak
rsdcf <- 30
sum(indexrsd <- apply(gr,1,function(x) ifelse(is.na(x[srm]),T,x[srm]<rsdcf)))
# overlap with rsd% and mean filter
sum(index <- indexmean&indexrsd)

# new list, update group and remove pool qc/blk and save the new csv file
qcindex <- grepl('blank',mzrt$group) | grepl('pool',mzrt$group)
mzrtfilter <- enviGCMS::getfilter(mzrt,rowindex = index,colindex = !qcindex, name = 'lif', type = 'm')
```

## Data visulization

```{r}
# you could load you eic and xset object, here is the demo data
data("srmeic")
data("srmxset")
# EIC for m/z 107.0502 and retention time 102.6s
plot(srmeic,srmxset,groupidx = 'M107.0502T102.6')
# PCA
enviGCMS::plotpca(data = mzrtfilter$data,lv = mzrtfilter$group)
# mzrt plot
enviGCMS::plotmr(mzrtfilter)
# RSD plot
enviGCMS::plotrsd(mzrtfilter)
# density plot
enviGCMS::plotden(mzrtfilter$data,lv=mzrtfilter$group)
# heatmap
enviGCMS::plothm(mzrtfilter$data,lv=factor(mzrtfilter$group),index = c(1:20))
```

## Normalization (Optional)

```{r ba}
# visulize the batch effect
mzrtsim::rlaplot(mzrt$data,lv = factor(mzrt$group))
mzrtsim::ridgesplot(mzrt$data,lv = factor(mzrt$group))
# get the simulation data and test on NOREVA
sim <- mzrtsim::simmzrt(mzrt$data)
mzrtsim::simdata(sim)
# correct the batch effect by sva and no sv found
mzrtcor <- mzrtsim::svacor(mzrt$data,lv = factor(mzrt$group))
# visulize the batch effect correction
# li <- mzrtsim::limmaplot(mzrtcor,lv = factor(mzrt$group$class))
# return the corrected data
# mzrt$data <- mzrtcor$dataCorrected
```

# Statistical analysis

```{r sa}
library(caret)
## Spliting data
trainIndex <- createDataPartition(mzrtfilter$group, p = .5, 
                                  list = FALSE, 
                                  times = 1)
## Get the training and testing datasets
train <- mzrtfilter$data[, trainIndex]
train <- cbind(Y=mzrtfilter$group[trainIndex],t(train))
test  <- mzrtfilter$data[,-trainIndex]
test  <- cbind(Y=mzrtfilter$group[-trainIndex],t(test))
## Train the model(random forest)
rfFit <- train(Y ~ ., data = train, 
                 method = "rf")
## find the top 10 important variables
Imp <- varImp(rfFit)
plot(Imp, top = 10)
# # Set the cross validation method
# fitControl <- trainControl(## 10-fold CV
#                            method = "repeatedcv",
#                            number = 10,
#                            ## repeated ten times
#                            repeats = 10)
## fit another model with cross validation
# lmFit <- train(Y ~ ., data = train[,c(1:5)], 
#                  method = "glm", 
#                  trControl = fitControl, 
#                  verbose = FALSE)
# ANOVA analysis for model selection
# anova(rfFit,lmFit)
```

# Annotation

```{r anno, eval=F}
library(xMSannotator)
data("adduct_weights")
data <- mzrtfilter$data
mz <- mzrtfilter$mz
time <- mzrtfilter$rt
data <- as.data.frame(cbind(mz, time, data))
data <- unique(data)
xMSannotator::multilevelannotation(
                                        dataA = data,
                                        max.mz.diff = 5,
                                        mode = 'pos',
                                        outloc = 'anno',
                                        db_name = 'HMDB',
                                        adduct_weights = adduct_weights,
                                        filter.by = c("M+H"),
                                        mass_defect_mode = 'pos',
                                        num_nodes = 4
)
```

# PMD analysis

```{r pmd, eval=F}
options(shiny.maxRequestSize = 100*1024^2)
pmd::runPMD()
```

Oxidation of Lorcainide.385.1687


# Connetion with other online database

## ISA for metabolights

```{r isa, eval=F}
# Risa package, pls download metadata from metabolights and put those file in current work dir
library(Risa)
test <- readISAtab()
metadata <- test@study.files$MTBLS822
# change the file name to load in the metabolites data
data0 <- read.table(file = 'm_e07_qm_fia_maf.tsv', sep = '\t', skip = 1)
head <- read.table(file = 'm_e07_qm_fia_maf.tsv',sep = '\t',nrows = 1)
data <- data0[,match(metadata$`Sample Name`,head,nomatch = F)]
colnames(data) <- head[,match(metadata$`Sample Name`,head,nomatch = F)]
group <- metadata[match(colnames(data),metadata$`Sample Name`,nomatch = F),]
mz <- data0[,head=='mass_to_charge']
rt <- data0[,head=='retention_time']
# construnt the list
list <- list(data=data,group=group,mz=mz,rt=rt)
```

## Metabolomics WorkBench

```{r mwb, eval=F}
# target list from certain study
list <- rmwf::getmwlist('ST000001')

# Untargeted data
# download demo files here: https://www.metabolomicsworkbench.org/data/DRCCMetadata.php?Mode=ProcessDownloadResults&StudyID=ST000553&AnalysisID=AN000845

group <- rmwf::getmwfactor('ST000553')

data <- read.table('ST000553_AN000846.txt',sep = '\t',header = T, nrows = 1983,na.strings = '\\N',row.names = 1)

anno <- read.table('ST000553_AN000846.txt',sep = '\t',header = T, skip = 1985,na.strings = '\\N',row.names = 1)
mz <- anno$quantified.m.z
rt <- anno$retention.index*60

list <- list(data=data,mz=mz,rt=rt,group=group)
```

